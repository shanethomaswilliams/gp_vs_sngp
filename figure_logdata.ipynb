{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, csv\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./sngp/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing our custom module(s)\n",
    "\n",
    "from sngp.model import RFFGP_Reg\n",
    "from sngp.loss import square_loss\n",
    "from sngp.train import train_model\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA:\", torch.cuda.get_device_name(device))\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "#     print(\"Using MPS (Apple Metal)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"Final device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving sngp figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on gp_vs_sngp/gaussian_process/true_gp.py lines 375-459\n",
    "#fig_path = /results/SNGP/dataset_nsamples/ or /results/SNGP/dataset_nsamples_seed/\n",
    "def save_fig_sngp(sngp, X_test, dataset, fig_path, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # ---- Determine extended range ----\n",
    "    x_test_1d = X_test.squeeze(-1)\n",
    "    x_min = x_test_1d.min().item()\n",
    "    x_max = x_test_1d.max().item()\n",
    "    x_range = x_max - x_min\n",
    "    \n",
    "    # Extend by 10% on each side\n",
    "    x_extended_min = x_min - 0.1*x_range\n",
    "    x_extended_max = x_max + 0.1*x_range\n",
    "    \n",
    "    #Commented out the following:\n",
    "    '''\n",
    "    # ---- Generate additional noisy test points in extended regions ----\n",
    "    # Sample ~50 points in each extended region\n",
    "    n_extra_left = 50\n",
    "    n_extra_right = 50\n",
    "    \n",
    "    x_extra_left = np.random.uniform(x_extended_min, x_min, n_extra_left)\n",
    "    x_extra_right = np.random.uniform(x_max, x_extended_max, n_extra_right)\n",
    "    x_extra = np.concatenate([x_extra_left, x_extra_right])\n",
    "    \n",
    "    # Generate noisy y values for these extra points\n",
    "    if dataset == \"Sin\":\n",
    "        y_extra = getSin(x_extra, noise=0.1)\n",
    "    elif dataset == \"CrazySin\":\n",
    "        y_extra = getCrazySin(x_extra, noise=0.1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "    \n",
    "    # Convert to torch and combine with original test set\n",
    "    X_extra = torch.tensor(x_extra, dtype=torch.float32).unsqueeze(-1)\n",
    "    X_test_extended = torch.cat([X_test, X_extra], dim=0)\n",
    "    '''\n",
    "    \n",
    "    # ---- Get predictions on extended test set ----\n",
    "    samples, mean, var = sngp.predict(X_test)      #Old: mean, var, cov = sngp.predict(X_test_extended)\n",
    "    std = torch.sqrt(var.clamp(min=1e-6))\n",
    "    \n",
    "    # Sort everything for plotting\n",
    "    x_extended_1d = X_test.squeeze(-1)              #Old: x_extended_1d = X_test_extended.squeeze(-1)\n",
    "    idx_extended = torch.argsort(x_extended_1d)\n",
    "    x_extended_sorted = x_extended_1d[idx_extended]\n",
    "    mean_sorted = mean[idx_extended]\n",
    "    std_sorted = std[idx_extended]\n",
    "    \n",
    "    # ---- Generate clean data for true function (dense for smooth line) ----\n",
    "    x_clean = np.linspace(x_extended_min, x_extended_max, 500)\n",
    "    \n",
    "    if dataset == \"Sin\":\n",
    "        y_clean = getSin(x_clean, noise=0.0)\n",
    "    elif dataset == \"CrazySin\":\n",
    "        y_clean = getCrazySin(x_clean, noise=0.0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "    \n",
    "    # ---- Plotting ----\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    # Confidence band (now extends to cover clean function range)\n",
    "    ax.fill_between(\n",
    "        x_extended_sorted.detach().numpy(),\n",
    "        (mean_sorted - 2*std_sorted).detach().numpy(),\n",
    "        (mean_sorted + 2*std_sorted).detach().numpy(),\n",
    "        alpha=0.3, color='blue', label='95% confidence (±2σ)'\n",
    "    )\n",
    "    \n",
    "    # Posterior mean\n",
    "    ax.plot(x_extended_sorted.detach().numpy(), mean_sorted.detach().numpy(), \n",
    "            'b-', linewidth=2, label='Posterior mean μ*')\n",
    "    \n",
    "    # True function (dotted line)\n",
    "    ax.plot(x_clean, y_clean, \n",
    "            'k--', linewidth=1, label='True function')\n",
    "    \n",
    "    ax.set_xlabel('x', fontsize=12)\n",
    "    ax.set_ylabel('y', fontsize=12)\n",
    "    ax.set_title('SNGP Regression: Full Closed Form', fontsize=14)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(x_extended_sorted.min().item(), x_extended_sorted.max().item())\n",
    "    ax.set_ylim(-3, 3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Meant to save rank vs. all metrics for a certain dataset (Sin or CrazySin) of size = n_samples in new file\n",
    "#Potentially at end of train.py or test.py in SNGP\n",
    "import os\n",
    "\n",
    "shared_dir = \"/results/SNGP/dataset_nsamples_seed/\"\n",
    "\n",
    "# Append summary to shared file \"likelyRank.csv\"\n",
    "with open(os.path.join(shared_dir, \"likelyRank.csv\"), \"a\") as f:\n",
    "    f.write(f\"{model.rank},{log_likelihood}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get plots of log_likelihood vs. rank fo dataset_nsample\n",
    "import csv\n",
    "\n",
    "rank = []\n",
    "LLHood = []\n",
    "\n",
    "with open(\"/results/SNGP/dataset_nsamples_seed/likelyRank.csv\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        epochs.append(int(row[\"epoch\"]))\n",
    "        losses.append(float(row[\"loss\"]))\n",
    "\n",
    "plt.plot(epochs, losses)\n",
    "plt.xlabel(\"Model Rank (Train Set Percentage)\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "plt.title(\"Log Likelihood vs Rank\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
